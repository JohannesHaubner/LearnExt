MaskNet(
  (network): Sequential(
    (0): PrependModule()
    (1): MLP_BN(
      (activation): ReLU()
      (bn): BatchNorm1d(3935, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (layers): Sequential(
        (0): BatchNorm1d(3935, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): Linear(in_features=8, out_features=64, bias=True)
        (2): ReLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): ReLU()
        (5): Linear(in_features=64, out_features=64, bias=True)
        (6): ReLU()
        (7): Linear(in_features=64, out_features=64, bias=True)
        (8): ReLU()
        (9): Linear(in_features=64, out_features=64, bias=True)
        (10): ReLU()
        (11): Linear(in_features=64, out_features=64, bias=True)
        (12): ReLU()
        (13): Linear(in_features=64, out_features=64, bias=True)
        (14): ReLU()
        (15): Linear(in_features=64, out_features=64, bias=True)
        (16): ReLU()
        (17): Linear(in_features=64, out_features=64, bias=True)
        (18): ReLU()
        (19): Linear(in_features=64, out_features=64, bias=True)
        (20): ReLU()
        (21): Linear(in_features=64, out_features=2, bias=True)
      )
    )
  )
  (base): TrimModule()
  (mask): TensorModule()
)